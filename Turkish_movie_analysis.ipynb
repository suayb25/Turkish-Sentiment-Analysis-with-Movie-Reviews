{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Turkish_movie_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9Lt36inA8bu",
        "colab_type": "code",
        "outputId": "4dc35c54-d712-4044-fc98-b652cccb9e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "column = ['yorum']\n",
        "df = pd.read_csv('yorumlar.csv',encoding ='iso-8859-9' ,sep='\"',nrows=20000)#7500\n",
        "df.columns=column\n",
        "df.info()\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19999 entries, 0 to 19998\n",
            "Data columns (total 1 columns):\n",
            "yorum    19999 non-null object\n",
            "dtypes: object(1)\n",
            "memory usage: 156.4+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>yorum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1\" Bu filmin katıldığı festivaller ödüllerini ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2\" çok komik bir film ya izlediğim en iyi kome...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3\" harbiden çooooooook iyiydi herkesin dediği ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4\" hayaller çok geniştir ve insanlar hayalleri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5\" o kadar sıcak ve samimi bir filmki tebrik e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               yorum\n",
              "0  1\" Bu filmin katıldığı festivaller ödüllerini ...\n",
              "1  2\" çok komik bir film ya izlediğim en iyi kome...\n",
              "2  3\" harbiden çooooooook iyiydi herkesin dediği ...\n",
              "3  4\" hayaller çok geniştir ve insanlar hayalleri...\n",
              "4  5\" o kadar sıcak ve samimi bir filmki tebrik e..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIbbeFL5gOA2",
        "colab_type": "text"
      },
      "source": [
        "**Cleaning Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c9Imsa-Kp5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,19999):\n",
        "  if (i>=100) and (i<1000):\n",
        "    str=df['yorum'][i]\n",
        "    a=str[4:].replace(\";\", \"\")\n",
        "    df['yorum'][i]=a\n",
        "  elif (i>=1000) and (i<10000):\n",
        "    str=df['yorum'][i]\n",
        "    a=str[6:].replace(\";\", \"\")\n",
        "    df['yorum'][i]=a\n",
        "  elif (i<100):\n",
        "    str=df['yorum'][i]\n",
        "    a=str[3:].replace(\";\", \"\")\n",
        "    df['yorum'][i]=a\n",
        "  elif (i>=10000):\n",
        "    str=df['yorum'][i]\n",
        "    a=str[8:].replace(\";\", \"\")\n",
        "    df['yorum'][i]=a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO9HPXwcgIw5",
        "colab_type": "code",
        "outputId": "62d035f1-e25e-4492-848a-54e8691a2a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df['yorum'][1500]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'görsel şovun yanında oyuncu kailtesi ve performansıyla güzel bir film diyebiliriz '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hp9H12nOWtM",
        "colab_type": "code",
        "outputId": "97d59d44-7d22-4768-89be-62d34e863926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "df['yorum'][:][:].value_counts()[df['yorum'][:][:].value_counts() == df['yorum'][:][:].value_counts().max()]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "harika bir film                                                                                         2\n",
              "Name: yorum, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9gRZoRYPfW4",
        "colab_type": "code",
        "outputId": "3dcd81fd-bdda-400b-d226-4b1d1e6b68f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from collections import Counter\n",
        "Counter(\" \".join(df[\"yorum\"]).split()).most_common(100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bir', 9219),\n",
              " ('ve', 5134),\n",
              " ('çok', 3783),\n",
              " ('film', 3670),\n",
              " ('bu', 3534),\n",
              " ('iyi', 2147),\n",
              " ('en', 1948),\n",
              " ('filmi', 1941),\n",
              " ('ama', 1852),\n",
              " ('de', 1673),\n",
              " ('güzel', 1660),\n",
              " ('kadar', 1503),\n",
              " ('da', 1502),\n",
              " ('daha', 1399),\n",
              " ('bi', 1301),\n",
              " ('için', 1156),\n",
              " ('filmin', 1076),\n",
              " ('gibi', 1050),\n",
              " ('o', 936),\n",
              " ('bence', 827),\n",
              " ('ne', 784),\n",
              " ('her', 724),\n",
              " ('filmde', 646),\n",
              " ('olarak', 644),\n",
              " ('gerçekten', 635),\n",
              " ('film.', 613),\n",
              " ('sonra', 577),\n",
              " ('ilk', 573),\n",
              " ('ile', 569),\n",
              " ('ki', 566),\n",
              " ('olan', 547),\n",
              " ('kesinlikle', 541),\n",
              " ('son', 533),\n",
              " ('harika', 519),\n",
              " ('tavsiye', 495),\n",
              " ('ben', 484),\n",
              " ('filme', 481),\n",
              " ('bile', 455),\n",
              " ('hiç', 447),\n",
              " ('mükemmel', 442),\n",
              " ('gereken', 437),\n",
              " ('cok', 420),\n",
              " ('Bu', 414),\n",
              " ('biraz', 408),\n",
              " ('var', 402),\n",
              " ('tek', 400),\n",
              " ('başarılı', 390),\n",
              " ('yine', 380),\n",
              " ('izlediğim', 352),\n",
              " ('&quot', 347),\n",
              " ('büyük', 342),\n",
              " ('böyle', 330),\n",
              " ('izleyin', 330),\n",
              " ('süper', 329),\n",
              " ('mutlaka', 327),\n",
              " (':)', 325),\n",
              " ('zaman', 313),\n",
              " ('biri', 311),\n",
              " ('filmlerden', 310),\n",
              " ('izledim', 306),\n",
              " ('sinema', 304),\n",
              " ('farklı', 304),\n",
              " ('diye', 303),\n",
              " ('10', 303),\n",
              " ('tam', 298),\n",
              " ('zaten', 297),\n",
              " ('önce', 296),\n",
              " ('Film', 295),\n",
              " ('yok', 295),\n",
              " ('ya', 292),\n",
              " ('aksiyon', 292),\n",
              " ('olduğunu', 289),\n",
              " ('şey', 288),\n",
              " ('nasıl', 287),\n",
              " ('fazla', 284),\n",
              " ('ise', 280),\n",
              " ('olduğu', 268),\n",
              " (',', 266),\n",
              " ('değil', 263),\n",
              " ('gayet', 257),\n",
              " ('özellikle', 253),\n",
              " ('sadece', 249),\n",
              " ('kötü', 248),\n",
              " ('Çok', 241),\n",
              " ('filmleri', 238),\n",
              " ('göre', 233),\n",
              " ('müthiş', 231),\n",
              " ('beni', 229),\n",
              " ('muhteşem', 227),\n",
              " ('filmden', 225),\n",
              " ('şekilde', 225),\n",
              " ('rağmen', 221),\n",
              " ('olmuş', 221),\n",
              " ('bana', 219),\n",
              " ('pek', 214),\n",
              " ('benim', 212),\n",
              " ('gerek', 212),\n",
              " ('aynı', 210),\n",
              " ('iki', 210),\n",
              " ('komedi', 207)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwzYhWuEQR_4",
        "colab_type": "code",
        "outputId": "1e21262e-7a76-4d6c-830c-f8e5238c410c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "set(df.yorum.apply(list).sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " '!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " '[',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '|',\n",
              " '\\x92',\n",
              " '\\x93',\n",
              " '\\x94',\n",
              " '´',\n",
              " 'Ç',\n",
              " 'Ö',\n",
              " '×',\n",
              " 'Ü',\n",
              " 'ß',\n",
              " 'à',\n",
              " 'á',\n",
              " 'â',\n",
              " 'æ',\n",
              " 'ç',\n",
              " 'è',\n",
              " 'é',\n",
              " 'î',\n",
              " 'ó',\n",
              " 'ö',\n",
              " '÷',\n",
              " 'û',\n",
              " 'ü',\n",
              " 'Ğ',\n",
              " 'ğ',\n",
              " 'İ',\n",
              " 'ı',\n",
              " 'Ş',\n",
              " 'ş'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDOkEDHIWXkw",
        "colab_type": "code",
        "outputId": "6f4a2cb2-1799-4641-be11-f4531d3a98cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 44.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 58.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (45.1.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/6d/7aae38a9022f982cf8167775c7fc299f203417b698c27080ce09060bba07/google_auth-1.11.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.11.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-1.11.0 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEMrQAClWftf",
        "colab_type": "code",
        "outputId": "0e7daef6-9538-42af-b465-2ee928b515cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb77fzJaJ7Ex",
        "colab_type": "code",
        "outputId": "16c5571f-e9c9-4e44-bd36-1a705a7a069d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df['result'] = 1\n",
        "df.result.iloc[10000:] = 0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIrEqYFfDZep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Tr2Eng = str.maketrans(\"çğıöşüÇĞIÖŞÜ\", \"cgiosuCGİOSU\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R45COAwuW9sG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d9c59ef8-db00-4562-abce-f1f24958774c"
      },
      "source": [
        "text=''\n",
        "for i in range(len(df['yorum'])):\n",
        "  df['yorum'][i] = df['yorum'][i].translate(Tr2Eng)\n",
        "  text=text+df['yorum'][i]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_C3GS_9DfGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = text.translate(Tr2Eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-oCoxjNC4Ca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_file = open(\"yorum.txt\", \"w\")\n",
        "n = text_file.write(text)\n",
        "text_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH-JrzxYSBlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YdKb4E4XRRX",
        "colab_type": "code",
        "outputId": "4f95cc52-bcd4-4e5e-b982-1886624fdbc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6727835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewSj46MzW8Qr",
        "colab_type": "code",
        "outputId": "4050ab2b-f76e-43b5-b367-9f769184e138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.texts_to_sequences([\"First\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[21, 2, 7, 9, 16]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR4yQUbdVouV",
        "colab_type": "code",
        "outputId": "f3e71b1c-b234-4f7a-9abd-3c6d30644fe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.sequences_to_texts([[21, 2, 7, 9, 16]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f i r s t']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyOrf7EAXCUY",
        "colab_type": "code",
        "outputId": "e70a049e-aa9a-4f79-f1ef-44d8765a6dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "max_id = len(tokenizer.word_index) # number of distinct characters\n",
        "dataset_size = tokenizer.document_count # total number of characters\n",
        "print(max_id)\n",
        "print(dataset_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84\n",
            "19999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbaTuMW8WD6W",
        "colab_type": "code",
        "outputId": "df5233a4-4734-4b38-f07b-f0fd62a652fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df['yorum'][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Bu filmin katildigi festivaller odullerini filmin anlattigi konuya, konuyu anlatimindaki ictenlige, salondan cikildiginda filmden alinan hazza, oyuncularin yeni ve onemsiz isimler olmalarina ragmen filme birseyler katip katmadiklarina gore dagitiyorlar ve bu filmde bunlarin hepsi vardi. Zetan festival jurisine karsi sert elestiriler yapan arkadasimizin istedigi ozellikleri de olsa film Oscar'a aday olur, hatta alirdi. Film tek kelime ile enfesti. İlk haftasinda sadece 2400 kisinin gitmesini ve GORa'nin onda biri kadar salonda gosterime girmesini Turk sinemaseverlerin!!! bir ayibi olarak goruyorum. Boyle filmleri siddetle sinema isletmecilerinden isteyelim ki gelecekte sinemamiz boyle idealist yonetmenler ile dolsun ve daha iyi yerlere gelelim. Turk sinemasi icin kult olacak bir film.Salt duygusal ve komik olmamis degisik renkler denenmis,filme dinamikler katilmis.İnce ayrintilar var,defalarca seyredilince fark ediliyor.Yore halkina gelince gercekten cok samimi olmus,herkes kendini oynamis,kimse rol yapacagim diye farkli sekillere burunmemis.Filmde olmasi gereken karakterler onlardi ve onlar da yapmasi gerekeni yapmislar.Muzik ise son derece duygusal,insandan birseyler kopartan bir Tulk halk ezgisi.Gemide ve Laleli'de Bir Azize gibi arsivime koydugum birkac filmden biri.Emegi gecen herkese tesekkur ediyorum. 1960'li yillar, kucuk bir Anadolu koyu olan Tepecik. Recep ve Mehmet, yazlari koylerinin yakinindaki Tavsanli kasabasinda ciraklik yaparlar. Recep bir karpuz saticisinin, Mehmet ise bir berberin yaninda calismaktadir. İkisi de sinemaya delicesine tutkundur. Bu tutku sonucunda geceleri koydeki evlerinin terkedilmis ahirinda bir yandan derme-catma bir film projeksiyon makinasi yapmaya calisirken, bir yandan da hayatlarini tumden degistirecek olan yonetmen olma hayalleri kurmaktadirlar. Onlarin bu konudaki ugraslarini ne kasabadaki fotografci, ne aileleri, ne de kasabadaki sinema salonunun sahibi ciddiye almaz. Sadece koyun delisi Omer cocuklarin sinema sevdasinin tanigi ve destekcisidir. izlenmeye deger enfes bir film...                                                                                    \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws2OBEXFXHr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#[encoded] = np.array(tokenizer.texts_to_sequences([\" \".join(df[\"yorum\"]).split()])) - 1\n",
        "[encoded] = np.array(tokenizer.texts_to_sequences([text])) - 1\n",
        "train_size = dataset_size * 90 // 100\n",
        "#dataset = tf.data.Dataset.from_tensor_slices(df['yorum'])\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcdmIwneS0F2",
        "colab_type": "code",
        "outputId": "a8653492-869e-4923-b491-2a1220e7adf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(encoded.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6732420,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvxYVLs3YNKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
        "dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBpbXKBbYQ9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXjmXiwyYTqP",
        "colab_type": "code",
        "outputId": "ed1cb3d6-88f8-4a40-ece6-faa9b7fca416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "for a in dataset.take(5):\n",
        "  print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[16 14  0 20  1  5  7  1  4  0  8  3 15 10  5  9 10 27 10  0 20  2 12 15\n",
            "  1 26  3  5  5  2  6  0 29  9 19  5  5  2  6  1  4  1  0 20  1  5  7  1\n",
            "  4  0  3  4  5  3 15 15 10 27 10  0  8 13  4 14 11  3 30  0  8 13  4 14\n",
            " 11 14  0  3  4  5  3 15 10  7 10  4  9  3  8  1  0  1 25 15  2  4  5  1\n",
            " 27  2 30  0 12], shape=(101,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[14  0 20  1  5  7  1  4  0  8  3 15 10  5  9 10 27 10  0 20  2 12 15  1\n",
            " 26  3  5  5  2  6  0 29  9 19  5  5  2  6  1  4  1  0 20  1  5  7  1  4\n",
            "  0  3  4  5  3 15 15 10 27 10  0  8 13  4 14 11  3 30  0  8 13  4 14 11\n",
            " 14  0  3  4  5  3 15 10  7 10  4  9  3  8  1  0  1 25 15  2  4  5  1 27\n",
            "  2 30  0 12  3], shape=(101,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[ 0 20  1  5  7  1  4  0  8  3 15 10  5  9 10 27 10  0 20  2 12 15  1 26\n",
            "  3  5  5  2  6  0 29  9 19  5  5  2  6  1  4  1  0 20  1  5  7  1  4  0\n",
            "  3  4  5  3 15 15 10 27 10  0  8 13  4 14 11  3 30  0  8 13  4 14 11 14\n",
            "  0  3  4  5  3 15 10  7 10  4  9  3  8  1  0  1 25 15  2  4  5  1 27  2\n",
            " 30  0 12  3  5], shape=(101,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[20  1  5  7  1  4  0  8  3 15 10  5  9 10 27 10  0 20  2 12 15  1 26  3\n",
            "  5  5  2  6  0 29  9 19  5  5  2  6  1  4  1  0 20  1  5  7  1  4  0  3\n",
            "  4  5  3 15 15 10 27 10  0  8 13  4 14 11  3 30  0  8 13  4 14 11 14  0\n",
            "  3  4  5  3 15 10  7 10  4  9  3  8  1  0  1 25 15  2  4  5  1 27  2 30\n",
            "  0 12  3  5 13], shape=(101,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[ 1  5  7  1  4  0  8  3 15 10  5  9 10 27 10  0 20  2 12 15  1 26  3  5\n",
            "  5  2  6  0 29  9 19  5  5  2  6  1  4  1  0 20  1  5  7  1  4  0  3  4\n",
            "  5  3 15 15 10 27 10  0  8 13  4 14 11  3 30  0  8 13  4 14 11 14  0  3\n",
            "  4  5  3 15 10  7 10  4  9  3  8  1  0  1 25 15  2  4  5  1 27  2 30  0\n",
            " 12  3  5 13  4], shape=(101,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwTiCrugYhOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRHbqw09YkSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0fq981OYmoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_JdPx-EYor1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iytg4iV-Yqvy",
        "colab_type": "code",
        "outputId": "33f25c14-3433-46ed-8c7b-405db30717c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for X_batch, Y_batch in dataset.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 100, 84) (32, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up0aJ3leYtWm",
        "colab_type": "code",
        "outputId": "7d4d7f7c-5a87-4562-e4f2-e9e910e0fbc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.argmax(X_batch[0,0:10,:],axis=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 0 0 0 0 0 0 0 0 0], shape=(10,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osR0n1G3YwcK",
        "colab_type": "code",
        "outputId": "116625bb-ee45-437f-882e-baa2bd71463a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "keras.backend.clear_session()\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]\n",
        "                     # no dropout in stateful RNN (https://github.com/ageron/handson-ml2/issues/32)\n",
        "                     # dropout=0.2, recurrent_dropout=0.2,\n",
        "                     ),\n",
        "    keras.layers.GRU(128, return_sequences=True\n",
        "                     # dropout=0.2, recurrent_dropout=0.2\n",
        "                    ),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n",
        "                    epochs=40)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 562 steps\n",
            "Epoch 1/40\n",
            "562/562 [==============================] - 11s 20ms/step - loss: 1.8571\n",
            "Epoch 2/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 1.0122\n",
            "Epoch 3/40\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.4156\n",
            "Epoch 4/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.2213\n",
            "Epoch 5/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.1755\n",
            "Epoch 6/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.1563\n",
            "Epoch 7/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.1442\n",
            "Epoch 8/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.1362\n",
            "Epoch 9/40\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.1306\n",
            "Epoch 10/40\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.1246\n",
            "Epoch 11/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.1205\n",
            "Epoch 12/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.1174\n",
            "Epoch 13/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.1146\n",
            "Epoch 14/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.1116\n",
            "Epoch 15/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.1101\n",
            "Epoch 16/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.1075\n",
            "Epoch 17/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.1059\n",
            "Epoch 18/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.1050\n",
            "Epoch 19/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.1032\n",
            "Epoch 20/40\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.1019\n",
            "Epoch 21/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.1008\n",
            "Epoch 22/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.1001\n",
            "Epoch 23/40\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.0987\n",
            "Epoch 24/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.0985\n",
            "Epoch 25/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.0972\n",
            "Epoch 26/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.0964\n",
            "Epoch 27/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.0962\n",
            "Epoch 28/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.0955\n",
            "Epoch 29/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.0947\n",
            "Epoch 30/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.0944\n",
            "Epoch 31/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.0941\n",
            "Epoch 32/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.0931\n",
            "Epoch 33/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.0930\n",
            "Epoch 34/40\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.0925\n",
            "Epoch 35/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.0923\n",
            "Epoch 36/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.0918\n",
            "Epoch 37/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.0915\n",
            "Epoch 38/40\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.0912\n",
            "Epoch 39/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.0907\n",
            "Epoch 40/40\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.0903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ffnwhXXBUZk",
        "colab_type": "code",
        "outputId": "ebe40d04-b7c4-4923-9938-40a3818e46cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, None, 128)         84480     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, None, 128)         99072     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, None, 90)          11610     \n",
            "=================================================================\n",
            "Total params: 195,162\n",
            "Trainable params: 195,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-IDLYdc5VuH",
        "colab_type": "code",
        "outputId": "4912e648-764f-4586-9f45-6c1022ef8657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 3)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dxY84-Ub2vP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j012G8aRb5tc",
        "colab_type": "code",
        "outputId": "9faa1667-1956-4836-f6eb-9145a8446bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_new = preprocess([\"Ben\"])\n",
        "Y_pred = model.predict_classes(X_new)\n",
        "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'c'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR4f3_nKcBOU",
        "colab_type": "code",
        "outputId": "d44d7523-1a3e-4ff9-c000-1226853f6764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_new = preprocess([\"Süper\"])\n",
        "Y_pred = model.predict_classes(X_new)\n",
        "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ecouBuWcHSW",
        "colab_type": "code",
        "outputId": "c9924b54-5cbe-4a98-8bfd-3d2cb7226173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_new = preprocess([\"Fil\"])\n",
        "Y_pred = model.predict_classes(X_new)\n",
        "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'m'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKPNiPkAc35p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model.predict(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1 #argmax\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbrdm0dbcsiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6rd3pj3cwJS",
        "colab_type": "code",
        "outputId": "1f004328-6d3e-4890-8ad9-a548ae433d28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "print(complete_text(\"Ben\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bence bir an önce gidip izleyin. emin olun beğeneceks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEYjP2FHdE7J",
        "colab_type": "code",
        "outputId": "d78b3473-4778-4be7-a241-3cc996ac89ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "print(complete_text(\"Süper\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Süper herkes izlesin :) http://tinypaste.com/528b8b36  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFHxzbuu4WwZ",
        "colab_type": "code",
        "outputId": "f98c6f79-b0c8-41b3-fa43-00232e226b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "print(complete_text(\"Fil\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filmi izlerken basta biraz tereddütte kaliniyor. ama \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teuD_AM0_Ppm",
        "colab_type": "code",
        "outputId": "36eebc95-9f39-40be-96fb-71a4230ec7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42) #7500 20 epoch\n",
        "\n",
        "print(complete_text(\"harik\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "harika...herkese tavsiye ederim...mutlaka izleyin...   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgKAl4X9zEBC",
        "colab_type": "code",
        "outputId": "0fc8f058-a9fd-44d0-c9da-82d966d97d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42) #7500 40 epoch\n",
        "\n",
        "print(complete_text(\"harik\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "harikaydı. sonuçta filmden daha iyi para vakit parmen f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3Vc5hmo4b7Q",
        "colab_type": "code",
        "outputId": "79158b4a-84fd-4844-eaa4-518154107e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42) #20 bin\n",
        "\n",
        "print(complete_text(\"harik\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "harika gerçoklar ki fal bir film.salt duygusal ve komik\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V5cjxRN25NW",
        "colab_type": "code",
        "outputId": "abbe4d04-d37d-4fe8-bfec-5dc631fdfbc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "print(complete_text(\"bi\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "biri.dede uyuşturucu bağımlısı ve seks düşkünü.amca \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBNFf_6l3BkH",
        "colab_type": "code",
        "outputId": "ba468791-ee54-4163-dd04-85e5bb8d1514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "print(complete_text(\"bu fi\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bu filmde bunların hepsi vardı. zetan festival jürisine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KBMinBUzJYg",
        "colab_type": "code",
        "outputId": "078381ea-f3f8-4d0f-f8c9-c409023153b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "print(complete_text(\"bu fi\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bu filmin katıldığı festivaller ödüllerini filmin anlat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN3jLzuv4pNA",
        "colab_type": "code",
        "outputId": "b9312d37-ed32-42f9-ee4c-322bf7ac107e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "print(complete_text(\"bu fi\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bu film özellikle james franco bunu çok güsell yansıtmı\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn6bW-1A4fns",
        "colab_type": "code",
        "outputId": "773468ad-e773-4abb-8b34-a3bddb502af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42) #7500 20 epoch\n",
        "print(complete_text(\"senary\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "senaryo..                                               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbh5D6DE4st4",
        "colab_type": "code",
        "outputId": "c512ec18-ba48-423f-ad49-f46c18d9ad8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42) #20 bin\n",
        "print(complete_text(\"senary\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "senaryo ve kurgu harika. i̇zleyin mutlaka               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEBeUNeSzOki",
        "colab_type": "code",
        "outputId": "b0b91c04-216d-4da7-851d-d842ac2ac19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42) #7500 40 epoch\n",
        "print(complete_text(\"senaryo iyi\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "senaryo iyi türk sineması adına böyle filmlerin olması çok se\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEifp_DX43cJ",
        "colab_type": "code",
        "outputId": "78502d48-caac-4a30-b53b-09d346d73ed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.random.set_seed(42) #20 bin\n",
        "print(complete_text(\"senaryo kötü\", temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "senaryo kötüp bir filmde hemen hemen her karede böylesine iyi \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo7gmeoUYQP4",
        "colab_type": "text"
      },
      "source": [
        "**Comments :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58evn7EZW5jz",
        "colab_type": "text"
      },
      "source": [
        "1) If we want better complete text results we need to use Turkish tokenizer. Results are not so good because the system is for English words.\n",
        "\n",
        "2) In this dataset, sentences are not so good, I mean sentences structure is \n",
        "broken so model is not training so good.\n",
        "\n",
        "3) Other thing is dataset is small. If we use a dataset which includes 50000 sentences text, results can be better than this.\n",
        "\n",
        "For Example: Turkish Pre-trained Word2Vec Model, Zemberek\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prD00WD3m-Ya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLqGTAsRsWwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=df['yorum'].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QzHjPJRrQm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = 10000\n",
        "tokenizer = Tokenizer(num_words = num_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyMrCcjhrUC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wUulFQcrlCo",
        "colab_type": "code",
        "outputId": "e62c0573-2198-4f5a-b177-626d6cd9eb13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "counter = 0\n",
        "for word in tokenizer.word_index:\n",
        "    counter = counter + 1\n",
        "    print(counter, \"-> \", word)\n",
        "    if(counter == 20):\n",
        "        break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 ->  bir\n",
            "2 ->  film\n",
            "3 ->  bu\n",
            "4 ->  ve\n",
            "5 ->  cok\n",
            "6 ->  ama\n",
            "7 ->  filmi\n",
            "8 ->  en\n",
            "9 ->  kadar\n",
            "10 ->  iyi\n",
            "11 ->  de\n",
            "12 ->  daha\n",
            "13 ->  10\n",
            "14 ->  bi\n",
            "15 ->  guzel\n",
            "16 ->  da\n",
            "17 ->  filmin\n",
            "18 ->  icin\n",
            "19 ->  gibi\n",
            "20 ->  ne\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1-8PEq5sw4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tokens = tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUVfSHAMs262",
        "colab_type": "code",
        "outputId": "3ae2a29c-ef81-436c-8a0f-0dd1eef12bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X[800]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Kitaba cok sagdik kalarak cekilmis,kitabi da cok guzeldi filmdi de cok guzel olmus ve en onemlisi kitabi kafalarina gore degistirmemisler '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJlsGzpBs7YM",
        "colab_type": "code",
        "outputId": "9970ca38-0017-4802-9aaa-a8a3cc36c71a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "np.array(X_train_tokens[800])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1342,    5, 7677,  314,  274,   16,    5,  156,   73,   11,    5,\n",
              "         15,   40,    4,    8, 1957,  274, 8507,   97])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j1qIKUhtteS",
        "colab_type": "code",
        "outputId": "b469c612-e234-41c4-e315-a4d89f8e51a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_tokens = [len(tokens) for tokens in X_train_tokens]\n",
        "num_tokens = np.array(num_tokens)\n",
        "num_tokens"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([203,  13,  14, ...,  46,  11,  26])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcVot7Xutzz-",
        "colab_type": "code",
        "outputId": "1799fd7f-19f2-43a4-b5b9-b7ef2d8f3ced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import math\n",
        "max_tokens = np.mean(num_tokens) + 2*np.std(num_tokens)\n",
        "max_tokens = math.ceil(max_tokens)\n",
        "max_tokens"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzQ3LzvGtE7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "X_train_pad = pad_sequences(X_train_tokens, maxlen = max_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMgfgN2Xt7Lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = tokenizer.word_index\n",
        "inverse_map = dict(zip(idx.values(), idx.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpyWvFbut-XF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokens_to_string(tokens):\n",
        "    words = (inverse_map[token] for token in tokens if token != 0)\n",
        "    text = \" \".join(words)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQROnOJduXog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = df['result'].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf404tLkeJeO",
        "colab_type": "code",
        "outputId": "ced281d7-7218-4970-ed42-b747506c50f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "keras.backend.clear_session()\n",
        "embed_size = 50\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Embedding(10000, embed_size,input_length=99),\n",
        "    keras.layers.GRU(128,return_sequences=True),\n",
        "    keras.layers.GRU(128),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "history= model.fit(X_train_pad,y_train,batch_size=16,epochs=10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 19999 samples\n",
            "Epoch 1/10\n",
            "19999/19999 [==============================] - 276s 14ms/sample - loss: 0.3180 - acc: 0.8619\n",
            "Epoch 2/10\n",
            "19999/19999 [==============================] - 274s 14ms/sample - loss: 0.1351 - acc: 0.9514\n",
            "Epoch 3/10\n",
            "19999/19999 [==============================] - 275s 14ms/sample - loss: 0.0725 - acc: 0.9758\n",
            "Epoch 4/10\n",
            "19999/19999 [==============================] - 274s 14ms/sample - loss: 0.0425 - acc: 0.9868\n",
            "Epoch 5/10\n",
            "19999/19999 [==============================] - 273s 14ms/sample - loss: 0.0296 - acc: 0.9909\n",
            "Epoch 6/10\n",
            "19999/19999 [==============================] - 273s 14ms/sample - loss: 0.0189 - acc: 0.9945\n",
            "Epoch 7/10\n",
            "19999/19999 [==============================] - 273s 14ms/sample - loss: 0.0168 - acc: 0.9954\n",
            "Epoch 8/10\n",
            "19999/19999 [==============================] - 273s 14ms/sample - loss: 0.0160 - acc: 0.9949\n",
            "Epoch 9/10\n",
            "19999/19999 [==============================] - 274s 14ms/sample - loss: 0.0086 - acc: 0.9970\n",
            "Epoch 10/10\n",
            "19999/19999 [==============================] - 276s 14ms/sample - loss: 0.0057 - acc: 0.9983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxLmyaNAzTNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c2da34f3-5c55-4d5b-f633-23c338bd1bfd"
      },
      "source": [
        "from numpy import array\n",
        "bad = \"bu film cok kotu\" #@param {type: \"string\"}\n",
        "good = \"bu film cok iyi senaryosu filan muthis\" #@param {type: \"string\"}\n",
        "for review in [good,bad]:\n",
        "    result = []\n",
        "    for word in review.split(\" \"):\n",
        "        result.append(idx[word])#id sine göre review i bulup içine yerleştirdik\n",
        "    tmp_padded = sequence.pad_sequences([result], maxlen=99)\n",
        "    print(\"%s. Predict Score: %s\" % (review,model.predict(array([tmp_padded][0]))[0][0]))#0'a ne kdar uzaksa o kadar pozitif"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bu film cok iyi senaryosu filan muthis. Predict Score: 0.9989661\n",
            "bu film cok kotu. Predict Score: 0.067014545\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}